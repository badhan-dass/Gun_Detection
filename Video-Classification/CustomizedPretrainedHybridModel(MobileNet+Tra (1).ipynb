{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4881826a-4900-43ed-b84f-f23453899a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import zipfile\n",
    "\n",
    "# # Specify the zip file path\n",
    "# zip_file_path = 'Gun_NoGun_Dataset_augmented.zip'\n",
    "\n",
    "# # Specify the extraction path\n",
    "# extract_path = '.'\n",
    "\n",
    "# # Open the zip file\n",
    "# with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "#     # Extract all files\n",
    "#     zip_ref.extractall(extract_path)\n",
    "\n",
    "# print(f'Zip file extracted to {extract_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79628168-369c-462f-a874-ef1b3e1e7080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from moviepy.editor import *\n",
    "import keras\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.layers import Dense, Input, RepeatVector, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Nadam, Adam\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, BatchNormalization, MaxPool2D, GlobalMaxPool2D\n",
    "from keras.layers import TimeDistributed, GRU, Dense, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe7e8fd-b73e-457d-bc9f-5d3d6e010c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.models import Sequential, Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3cd6a4-a4a6-4a78-8b5e-0d0b40abd271",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_constant = 23\n",
    "np.random.seed(seed_constant)\n",
    "random.seed(seed_constant)\n",
    "tf.random.set_seed(seed_constant)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69eee8d-a3d1-4bd6-b403-c410182a9b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir =  \"UCF_crime_subset//\"\n",
    "IMAGE_HEIGHT, IMAGE_WIDTH= 224,224\n",
    "\n",
    "SEQUENCE_LENGTH =50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1901d2-fa71-4604-8fea-d17930c83387",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_categories_list = [\"Gun\", \"NoGun\"]\n",
    "model_output_length = len(class_categories_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8d0353-8edc-48de-baf1-7da24a58a848",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pixel_value = 255\n",
    "def extract_frame(video_path):\n",
    "  # frames_list = []\n",
    "\n",
    "  # #print(\" the video file path is : {}\".format(video_path))\n",
    "  # videoObj = cv2.VideoCapture(video_path)\n",
    "  # #print(\"the video object is: {}\".format(videoObj))\n",
    "\n",
    "  # \"\"\" Iterating through Video Frames \"\"\"\n",
    "  # while True:\n",
    "\n",
    "  #   # Reading a frame from the video file\n",
    "  #   success, image = videoObj.read()\n",
    "  #   #print(\"the value of success is: {}\".format(success))\n",
    "\n",
    "  #   if not success:\n",
    "  #     break\n",
    "\n",
    "  #   resized_frame = cv2.resize(image, (image_height, image_width))\n",
    "\n",
    "  #   \"\"\"Normalize the resized frame by dividing it with 255 so that \n",
    "  #   each pixel value then lies between 0 and 1\"\"\"\n",
    "\n",
    "  #   normalized_frame = resized_frame / max_pixel_value\n",
    "  #   frames_list.append(normalized_frame)\n",
    "\n",
    "    \n",
    "  # videoObj.release()\n",
    "\n",
    "\n",
    "    frames_list = []\n",
    "    \n",
    "    # Read the Video File\n",
    "    video_reader = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Get the total number of frames in the video.\n",
    "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Calculate the the interval after which frames will be added to the list.\n",
    "    skip_frames_window = max(int(video_frames_count/SEQUENCE_LENGTH), 1)\n",
    "    \n",
    "    # Iterate through the Video Frames.\n",
    "    for frame_counter in range(SEQUENCE_LENGTH):\n",
    "    \n",
    "        # Set the current frame position of the video.\n",
    "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
    "    \n",
    "        # Reading the frame from the video. \n",
    "        success, frame = video_reader.read() \n",
    "    \n",
    "        if not success:\n",
    "            break\n",
    "    \n",
    "        # Resize the Frame to fixed height and width.\n",
    "        resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "        \n",
    "        # Normalize the resized frame\n",
    "        normalized_frame = resized_frame / 255\n",
    "        \n",
    "        # Append the normalized frame into the frames list\n",
    "        frames_list.append(normalized_frame)\n",
    "    \n",
    "    \n",
    "    video_reader.release()\n",
    "\n",
    "\n",
    "    return frames_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943a452f-3497-4bdb-8c45-51d27da91e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_creation():\n",
    "\n",
    "    features = []\n",
    "    labels = []\n",
    "    video_files_paths = []\n",
    "    \n",
    "    # Iterating through all the classes.\n",
    "    for class_index, class_name in enumerate(class_categories_list):\n",
    "        \n",
    "        print(f'Extracting Data of Class: {class_name}')\n",
    "        \n",
    "        # Get the list of video files present in the specific class name directory.\n",
    "        files_list = os.listdir(os.path.join(data_dir, class_name))\n",
    "        \n",
    "        # Iterate through all the files present in the files list.\n",
    "        for file_name in files_list:\n",
    "            \n",
    "            # Get the complete video path.\n",
    "            video_file_path = os.path.join(data_dir, class_name, file_name)\n",
    " \n",
    "            # Extract the frames of the video file.\n",
    "            frames = extract_frame(video_file_path)\n",
    " \n",
    "            # Check if the extracted frames are equal to the SEQUENCE_LENGTH specified.\n",
    "            # So ignore the videos having frames less than the SEQUENCE_LENGTH.\n",
    "            if len(frames) == SEQUENCE_LENGTH:\n",
    " \n",
    "                # Append the data to their repective lists.\n",
    "                features.append(frames)\n",
    "                labels.append(class_index)\n",
    "                video_files_paths.append(video_file_path)\n",
    " \n",
    "    features = np.asarray(features)\n",
    "    labels = np.array(labels)  \n",
    "\n",
    "    return features, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8318f13-5f00-4ccf-bfde-5f469c9c19eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = data_creation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e29e94-5e4b-466c-87c4-710328f43f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"the shape of the feature = {}\".format(features.shape))\n",
    "print(\"the shape of the labels = {}\".format(labels.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a591ab-de67-4797-bdf8-8e35f8d138a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_labels = to_categorical(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ff7c15-6485-437f-9c2e-a556d7ac3aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, one_hot_encoded_labels, \n",
    "                                                                            test_size = 0.5, \n",
    "                                                                            shuffle = True, \n",
    "                                                                            random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3bc01e-72fb-4b03-a98d-542d51bd7979",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"the shape of the feature = {}\".format(features_train.shape))\n",
    "print(\"the shape of the labels = {}\".format(labels_train.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8935243-0edb-4d1a-a2fc-a5beeb6933b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"the shape of the feature = {}\".format(features_test.shape))\n",
    "print(\"the shape of the labels = {}\".format(labels_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab9657e-4d72-4f4f-bd0d-7a70b8e3c12f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "no_of_channels = 3\n",
    "\n",
    "# Load the saved model\n",
    "mobileNet_model = load_model('MobileNet_Date_Time_2024_08_17__15_45_52___Loss_0.05901234969496727___Accuracy_0.9815759658813477.h5')\n",
    "\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (IMAGE_HEIGHT, IMAGE_WIDTH, no_of_channels)\n",
    "\n",
    "# Remove the classification head (last layer)\n",
    "mobileNet_model = Model(inputs=mobileNet_model.inputs, outputs=mobileNet_model.layers[-5].output)\n",
    "\n",
    "# Set the new input shape\n",
    "#mobileNet_model.build(input_shape)\n",
    "\n",
    "# Print the updated model summary\n",
    "mobileNet_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7db383-fee1-431e-b2a1-44843a124825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37e3d45-9841-42fe-a1c6-a17c94829adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobileNet_input = Input(shape=(SEQUENCE_LENGTH,\n",
    "                           IMAGE_HEIGHT,\n",
    "                            IMAGE_WIDTH,\n",
    "                            no_of_channels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fd0039-8d53-494a-8bd7-4d0a053b263f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Add, Dense, Input, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db999892-7656-4766-9e1d-ebb3fb8d3cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_frames_encoded = TimeDistributed(mobileNet_model)(mobileNet_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d158e9-aa6e-4e84-8da6-84075f391601",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325d9785-25f2-4870-9736-0d4b6ad3ad20",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_frames_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133bd4c9-8327-4ec0-979e-c8521aa2fb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_classes = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a64332d-2776-49d0-8ed9-5c3af7676670",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the Transformer model for sequential video frames processing\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Multi-head self-attention\n",
    "    attention_output = MultiHeadAttention(num_heads=num_heads, key_dim=head_size)(inputs, inputs)\n",
    "    attention_output = Dropout(dropout)(attention_output)\n",
    "    \n",
    "    # Add & Normalize\n",
    "    attention_output = Add()([attention_output, inputs])\n",
    "    attention_output = LayerNormalization(epsilon=1e-6)(attention_output)\n",
    "    \n",
    "    # Feed-forward part\n",
    "    ff_output = Dense(ff_dim, activation=\"relu\")(attention_output)\n",
    "    ff_output = Dropout(dropout)(ff_output)\n",
    "    ff_output = Dense(inputs.shape[-1])(ff_output)\n",
    "    \n",
    "    # Add & Normalize\n",
    "    ff_output = Add()([ff_output, attention_output])\n",
    "    ff_output = LayerNormalization(epsilon=1e-6)(ff_output)\n",
    "    \n",
    "    return ff_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3f5ee4-1c5c-4b65-8865-8bdf3c791d0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1786e6c3-eb7d-4c43-94e1-87879d62da67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer Encoder\n",
    "transformer_output = transformer_encoder(video_frames_encoded, head_size=256, num_heads=4, ff_dim=512, dropout=0.1)\n",
    "\n",
    "# Global pooling layer (optional, depending on your use case)\n",
    "transformer_output = GlobalAveragePooling1D()(transformer_output)\n",
    "\n",
    "# Hidden layers (same as before)\n",
    "hidden_layer1 = Dense(1024, activation=\"relu\")(transformer_output)\n",
    "hidden_layer2 = Dense(512, activation=\"relu\")(hidden_layer1)\n",
    "hidden_layer3 = Dense(256, activation=\"relu\")(hidden_layer2)\n",
    "hidden_layer4 = Dense(128, activation=\"relu\")(hidden_layer3)\n",
    "hidden_layer5 = Dense(64, activation=\"relu\")(hidden_layer4)\n",
    "\n",
    "\n",
    "# Add output layer\n",
    "outputs = Dense(no_of_classes, activation=\"softmax\")(hidden_layer5)\n",
    "\n",
    "# Define the model\n",
    "model = Model([mobileNet_input], outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4690bef4-3c70-4796-9219-7105a62eb621",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.00001)\n",
    "                  # beta_1=0.9,\n",
    "                  # beta_2=0.999,\n",
    "                  # epsilon=1e-08,\n",
    "                  # weight_decay=0.004)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13492e04-2f4f-4d39-896c-1a357a2757ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e80d2e-e297-4476-a85d-10a01f46c867",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b291f04b-07ce-453c-ae4e-4587efefa47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Early Stopping Callback\n",
    "early_stopping_callback = EarlyStopping(monitor=\"val_loss\",\n",
    "                      mode=\"min\",\n",
    "                      restore_best_weights=True,\n",
    "                      patience=10)\n",
    "checkpoint = ModelCheckpoint('MobileNet+transformer(UCF_Crime(50-50))_best_weights.keras',\n",
    "                             monitor='val_accuracy',\n",
    "                            #  monitor='val_f1_score',\n",
    "                             verbose=1,\n",
    "                             mode='max',\n",
    "                             save_best_only=True)\n",
    "callbacks = [early_stopping_callback, checkpoint]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0237416-13bd-4356-8110-b860c3a7c5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train.shape, labels_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f9ba48-922e-483a-a643-d40e16044ab4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start Training\n",
    "model_training_history = model.fit(x = features_train, \n",
    "                                   y = labels_train, \n",
    "                                   epochs = 150, \n",
    "                                   batch_size = 16,\n",
    "                                   shuffle = True, \n",
    "                                   callbacks=[callbacks],\n",
    "                                   validation_split = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2255e125-e7cd-405e-8c76-e0b65d4521a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf7356f-7d79-42cf-ae47-0377e61ad03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime as dt\n",
    "\n",
    "# model2_evaluation_history = model.evaluate(features_test, labels_test)\n",
    "\n",
    "# date_time_format = '%Y_%m_%d__%H_%M_%S'\n",
    "# current_date_time_dt = dt.datetime.now()\n",
    "\n",
    "# current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)\n",
    "# model_evaluation_loss, model_evaluation_accuracy = model2_evaluation_history\n",
    "# model_name = f'Model___Date_Time_{current_date_time_string}___Loss_{model_evaluation_loss}___Accuracy_{model_evaluation_accuracy}.h5'\n",
    "# # Saving your Model\n",
    "# model.save(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462fb82a-1e5f-4c6d-9c47-3fb1cdfd8128",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed01c47a-eaf7-4edb-89a1-2f81191e9414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7a3824-c046-4049-aecd-0f49026c4256",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels_pred = model.predict(features_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f6d852-903a-4b01-8d13-88f304d77b5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3fa9bf-b963-4ee2-998d-6f04d01b0768",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pred1 = np.argmax(labels_pred, axis = 1)\n",
    "labels_test = np.argmax(labels_test, axis = 1)\n",
    "labels_pred1, labels_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0e471e-a0cb-47d4-89e3-633a26cc0442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(labels_test, labels_pred1)\n",
    "\n",
    "# Print the report\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a534861-e555-4a08-9b66-ef9a7bb76362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "def plot_metric(measure_name_1, measure_name_2, plot_title):\n",
    "  \n",
    " \n",
    "  measure_value_1 = model_training_history.history[measure_name_1]\n",
    "  measure_value_2 = model_training_history.history[measure_name_2] \n",
    "  epochs = range(len(measure_value_1))\n",
    "\n",
    "  plt.plot(epochs, measure_value_1, 'blue', label = measure_name_1)\n",
    "  plt.plot(epochs, measure_value_2, 'red', label = measure_name_2)   \n",
    "\n",
    "  plt.title(str(plot_title))\n",
    "  plt.legend()\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ed272e-7af6-4ff1-8df1-b92c6139334a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric('loss', 'val_loss', 'Total Training Loss vs Total Validation Loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d88c8b-177e-4fab-a3f7-0be5ae9915dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric('accuracy', 'val_accuracy', 'Total Accuracy vs Total Validation Accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d9deef-e07c-486b-86b1-ba3e8f1124b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a1c225-6070-4719-a440-3804bf2069d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7679e01-65a0-4e65-9752-3e07a5644de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37e0fed-d033-4bc1-b123-7b7ba1ab0c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(labels_test, labels_pred[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "auc_score = roc_auc_score(labels_test, labels_pred[:, 1])\n",
    "print(auc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc950c7-e9b5-4a47-8f51-fcc3dec0e350",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81879f5c-cb19-4be1-bebb-776859eae031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a093cf6-9133-486a-9052-f83cf2800011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62594a8d-640c-4e38-82ae-516522137f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c894cfcb-d034-4c97-a4db-7f4f74779a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4016f105-c131-49f8-8f7d-4590472b37a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7182ae4c-c033-4475-b39d-e4408f440a24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e7181d-172e-41fc-8b22-7d217135ed30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d13c1b-3795-4c8c-98ac-6eb0b0b42292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfccfc07-5b38-4922-9c71-c67a80e0118c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08245b91-c4bf-4d47-bf13-a4c610bcd48e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2002e0ce-833b-4d84-89fc-62e3f15db34b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
